{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","import re\n","import os\n","import string\n","from sklearn.model_selection import train_test_split\n","import shutil\n","import tensorflow as tf\n","from transformers import AutoTokenizer\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T13:59:21.164672Z","iopub.status.busy":"2023-09-03T13:59:21.163037Z","iopub.status.idle":"2023-09-03T13:59:21.173144Z","shell.execute_reply":"2023-09-03T13:59:21.171847Z","shell.execute_reply.started":"2023-09-03T13:59:21.164619Z"},"trusted":true},"outputs":[],"source":["def custom_standardization(input_data):\n","    lowercase = tf.strings.lower(input_data)\n","    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n","    return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')\n","\n","def get_text_label(raw_ds):\n","    list_text, list_label = [], []\n","    for data, _label in raw_ds:\n","        text = custom_standardization(data)\n","        revised_text = [t.numpy().decode('utf-8').replace('  ', ' ').strip() for t in text]\n","        label = _label.numpy().tolist()\n","        list_text.extend(revised_text)\n","        list_label.extend(label)\n","    return list_text, list_label"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T13:59:25.108670Z","iopub.status.busy":"2023-09-03T13:59:25.108287Z","iopub.status.idle":"2023-09-03T14:00:08.332838Z","shell.execute_reply":"2023-09-03T14:00:08.331806Z","shell.execute_reply.started":"2023-09-03T13:59:25.108638Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","84125825/84125825 [==============================] - 9s 0us/step\n","['imdb.vocab', 'README', 'test', 'train', 'imdbEr.txt']\n","Train Directory: ['neg', 'unsupBow.feat', 'unsup', 'labeledBow.feat', 'urls_unsup.txt', 'urls_neg.txt', 'urls_pos.txt', 'pos']\n","Test Directory: ['neg', 'labeledBow.feat', 'urls_neg.txt', 'urls_pos.txt', 'pos']\n","Found 25000 files belonging to 2 classes.\n","Found 25000 files belonging to 2 classes.\n"]}],"source":["# Get IMDB Dataset\n","url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n","dataset = tf.keras.utils.get_file('aclImdb_v1', url, untar=True, cache_dir='', cache_subdir='')\n","dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb') # '/tmp/.keras/aclImdb'\n","\n","# Check files in folder\n","print(os.listdir(dataset_dir))\n","train_dir = os.path.join(dataset_dir, 'train')\n","print(f'Train Directory: {os.listdir(train_dir)}')\n","test_dir = os.path.join(dataset_dir, 'test')\n","print(f'Test Directory: {os.listdir(test_dir)}')\n","\n","# Remove Necessary\n","remove_dir = os.path.join(train_dir, 'unsup')\n","shutil.rmtree(remove_dir)\n","\n","# Extract Dataset from Data files\n","batch_size = 32\n","seed = 42\n","\n","raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n","    '/tmp/.keras/aclImdb/train',\n","    batch_size = batch_size,\n","    shuffle=False\n",")\n","# raw_valid_ds = tf.keras.utils.text_dataset_from_directory(\n","# '/tmp/.keras/aclImdb/train',\n","# batch_size = batch_size,\n","# validation_split = 0.2,\n","# subset='validation',\n","# seed=seed)\n","\n","raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n","    '/tmp/.keras/aclImdb/test',\n","    shuffle=False,\n","    batch_size = batch_size)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T14:00:08.334953Z","iopub.status.busy":"2023-09-03T14:00:08.334590Z","iopub.status.idle":"2023-09-03T14:00:27.970336Z","shell.execute_reply":"2023-09-03T14:00:27.968592Z","shell.execute_reply.started":"2023-09-03T14:00:08.334907Z"},"trusted":true},"outputs":[],"source":["# Train Data split into Train & Valid\n","raw_text, raw_label = get_text_label(raw_train_ds)\n","train_text, val_text, train_label, val_label = train_test_split(raw_text, raw_label, test_size=0.2, random_state=42)\n","test_text, test_label = get_text_label(raw_test_ds)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T14:00:49.892181Z","iopub.status.busy":"2023-09-03T14:00:49.891727Z","iopub.status.idle":"2023-09-03T14:00:53.052804Z","shell.execute_reply":"2023-09-03T14:00:53.051583Z","shell.execute_reply.started":"2023-09-03T14:00:49.892149Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"245126ecd8994e7abfcd42bbda51f6b4","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb2602a31e254d3bad03b21b7f4a418f","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d67a0bf7508848449ed3368214b68168","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76aa72417fbc479180c8833909402815","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
