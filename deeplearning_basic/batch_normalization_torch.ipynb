{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sample Embedding 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.9269,  1.4873,  0.9007, -2.1055],\n",
      "         [ 0.6784, -1.2345, -0.0431, -1.6047],\n",
      "         [-0.7521,  1.6487, -0.3925, -1.4036],\n",
      "         [-0.7279, -0.5594, -0.7688,  0.7624],\n",
      "         [ 1.6423, -0.1596, -0.4974,  0.4396]],\n",
      "\n",
      "        [[-0.7581,  1.0783,  0.8008,  1.6806],\n",
      "         [ 0.0349,  0.3211,  1.5736, -0.8455],\n",
      "         [ 1.3123,  0.6872, -1.0892, -0.3553],\n",
      "         [-1.4181,  0.8963,  0.0499,  2.2667],\n",
      "         [ 1.1790, -0.4345, -1.3864, -1.2862]]])\n"
     ]
    }
   ],
   "source": [
    "batch, sentence_len, embed_dim = 2, 4, 5\n",
    "batch_embed = torch.randn(batch, embed_dim, sentence_len)\n",
    "print(batch_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nn.BatchNorm1d 함수를 사용한 Nomalize \n",
    "    * batch을 기준으로 $\\mu, \\sigma^2$를 이용하여 Normalize\n",
    "    * nn.BatchNorm1d은 입력을 (batch, embed_dim, sentence_len)으로 받으므로 transpose를 통해 (batch, sentence_len, embed_dim)으로 형태를 변경\n",
    "    * batch 내의 동일한 위치의 embedding 값을 기준으로 $\\mu, \\sigma^2$를 계산\n",
    "        * eg. $\\mu_{1} = \\frac{(embed_{1,1} + embed_{2,1} + embed_{3,1} + ... + embed_{batch size, 1})}{batch size}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0112,  0.6694,  0.2133, -2.1240],\n",
      "         [ 0.8342, -1.1157,  0.0988, -1.4930],\n",
      "         [-0.6723,  1.6039, -0.3313, -1.2899],\n",
      "         [-0.7092, -0.5581, -0.7460,  0.6279],\n",
      "         [ 1.6754, -0.0950, -0.4269,  0.4937]],\n",
      "\n",
      "        [[-1.0764,  0.3514,  0.1356,  0.8197],\n",
      "         [ 0.1783,  0.4700,  1.7466, -0.7191],\n",
      "         [ 1.2850,  0.6923, -0.9918, -0.2960],\n",
      "         [-1.3285,  0.7479, -0.0114,  1.9775],\n",
      "         [ 1.2202, -0.3651, -1.3004, -1.2020]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_1d_norm = nn.BatchNorm1d(embed_dim)\n",
    "output = batch_1d_norm(batch_embed)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Batch Normalization 구현 \n",
    "* $y = \\frac{x - E[x]}{\\sqrt{Var[x] + \\epsilon}}*\\gamma + \\beta$\n",
    "* $\\gamma, \\beta$는 학습 가능한 paramters( weight, bias )\n",
    "* var 계산 시, unbiased=False으로 설정하지 않으면 Bessel’s correction을 통해 표본 크기를 n이 아닌 n-1을 사용하게 된다)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:\n",
      "  tensor([ 0.6264, -0.1400, -0.0431,  0.0626, -0.0629])\n",
      " \n",
      "var:\n",
      " tensor([1.6543, 0.9625, 1.1125, 1.2423, 1.0358])\n"
     ]
    }
   ],
   "source": [
    "batch_embed = batch_embed.transpose(1, 2)\n",
    "eg_mean = torch.mean(batch_embed, dim=(0, 1))\n",
    "print('mean:\\n ', eg_mean)\n",
    "print(' ')\n",
    "eg_var = torch.var(batch_embed, dim=(0, 1), unbiased = False)\n",
    "print('var:\\n', eg_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0112,  0.6694,  0.2133, -2.1240],\n",
      "         [ 0.8342, -1.1157,  0.0988, -1.4930],\n",
      "         [-0.6723,  1.6039, -0.3313, -1.2899],\n",
      "         [-0.7092, -0.5581, -0.7460,  0.6279],\n",
      "         [ 1.6754, -0.0950, -0.4269,  0.4937]],\n",
      "\n",
      "        [[-1.0764,  0.3514,  0.1356,  0.8197],\n",
      "         [ 0.1783,  0.4700,  1.7466, -0.7191],\n",
      "         [ 1.2850,  0.6923, -0.9918, -0.2960],\n",
      "         [-1.3285,  0.7479, -0.0114,  1.9775],\n",
      "         [ 1.2202, -0.3651, -1.3004, -1.2020]]], grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 위의 결과와 동일\n",
    "eg_x_hat = (batch_embed - eg_mean) / torch.sqrt(eg_var + batch_1d_norm.eps)\n",
    "print((batch_1d_norm.weight * eg_x_hat + batch_1d_norm.bias).transpose(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.8371, -0.9224,  1.8113,  0.1606,  0.3672],\n",
      "          [ 0.1754,  1.3852, -0.4459, -1.2024,  0.7078],\n",
      "          [-1.0759,  0.5357,  1.1754,  0.5612, -0.4527],\n",
      "          [-0.7718,  0.1453,  0.2311,  0.0087, -0.1423],\n",
      "          [ 0.1971, -1.1441,  0.3383,  1.6992,  2.8140]],\n",
      "\n",
      "         [[ 0.3598, -0.0898,  0.4584, -0.5644,  1.0563],\n",
      "          [-1.4692,  1.4332,  0.7281, -0.7106, -0.6021],\n",
      "          [ 0.9604,  0.4048, -1.3543, -0.4976,  0.4747],\n",
      "          [-0.1976,  1.2683,  1.2243,  0.0981,  1.7423],\n",
      "          [-1.3527,  0.2191,  0.5526, -0.6788,  0.5743]],\n",
      "\n",
      "         [[ 0.1877, -0.3576, -0.3165,  0.5886, -0.8905],\n",
      "          [ 0.4098, -0.9864,  0.1233,  0.3499,  0.6173],\n",
      "          [-0.1693,  0.2332,  4.0356,  1.2795,  1.0311],\n",
      "          [-0.7048,  1.0131, -0.3308,  0.5177,  0.3878],\n",
      "          [-0.5797, -0.1691, -0.5733,  0.5069, -0.4752]]],\n",
      "\n",
      "\n",
      "        [[[-0.4920,  0.2704, -0.5628,  0.6793,  0.4405],\n",
      "          [-0.3609, -0.0606,  0.0733,  0.8187,  1.4805],\n",
      "          [ 0.3449, -1.4241, -0.1163,  0.2176, -0.0467],\n",
      "          [-1.4335, -0.5665, -0.4253,  0.2625, -1.4391],\n",
      "          [ 0.5214,  1.0414, -0.3997, -2.2933,  0.4976]],\n",
      "\n",
      "         [[-0.4257, -1.3371, -0.1933,  0.6526, -0.3063],\n",
      "          [-0.3302, -0.9808,  0.1947, -1.6535,  0.6814],\n",
      "          [ 1.4611, -0.3098,  0.9633, -0.3095,  0.5712],\n",
      "          [ 1.1179, -1.2956,  0.0503, -0.5855, -0.3900],\n",
      "          [ 0.9812, -0.6401, -0.4908,  0.2080, -1.1586]],\n",
      "\n",
      "         [[-0.9637, -0.3750,  0.8033,  0.7165,  1.5335],\n",
      "          [-1.4510, -0.7861, -0.9563, -1.2476, -0.5778],\n",
      "          [ 0.3255, -0.8146, -1.0212, -0.4949, -0.5923],\n",
      "          [ 0.1543,  0.4408,  0.3125, -0.0335, -0.3980],\n",
      "          [ 1.0805, -1.7809,  1.5080,  0.3094, -0.5003]]]])\n"
     ]
    }
   ],
   "source": [
    "batch, channel, height, width = 2, 3, 5, 5\n",
    "batch_img = torch.randn(batch, channel, height, width)\n",
    "print(batch_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nn.BatchNorm1d 함수를 사용한 Nomalize \n",
    "    * batch을 기준으로 $\\mu, \\sigma^2$를 이용하여 Normalize\n",
    "    * nn.BatchNorm1d은 입력을 (batch, channel, height, width)으로 받으므로 permute를 통해 (batch, height, width, channel)으로 형태를 변경\n",
    "    * batch 내의 동일한 위치의 channel 값을 기준으로 $\\mu, \\sigma^2$를 계산\n",
    "        * eg. $\\mu_{1} = \\frac{(channel{1,1,1} + channel{1,2,1} + channel{1,3,1} + ... + channel{1,batch size, 1})}{batch size}$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
