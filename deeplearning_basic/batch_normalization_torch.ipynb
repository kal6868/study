{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sample Embedding 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.9269,  1.4873,  0.9007, -2.1055],\n",
      "         [ 0.6784, -1.2345, -0.0431, -1.6047],\n",
      "         [-0.7521,  1.6487, -0.3925, -1.4036],\n",
      "         [-0.7279, -0.5594, -0.7688,  0.7624],\n",
      "         [ 1.6423, -0.1596, -0.4974,  0.4396]],\n",
      "\n",
      "        [[-0.7581,  1.0783,  0.8008,  1.6806],\n",
      "         [ 0.0349,  0.3211,  1.5736, -0.8455],\n",
      "         [ 1.3123,  0.6872, -1.0892, -0.3553],\n",
      "         [-1.4181,  0.8963,  0.0499,  2.2667],\n",
      "         [ 1.1790, -0.4345, -1.3864, -1.2862]]])\n"
     ]
    }
   ],
   "source": [
    "batch, sentence_len, embed_dim = 2, 4, 5\n",
    "batch_embed = torch.randn(batch, embed_dim, sentence_len)\n",
    "print(batch_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nn.BatchNorm1d 함수를 사용한 Nomalize \n",
    "    * batch을 기준으로 $\\mu, \\sigma^2$를 이용하여 Normalize\n",
    "    * nn.BatchNorm1d은 입력을 (batch, embed_dim, sentence_len)으로 받으므로 transpose를 통해 (batch, sentence_len, embed_dim)으로 형태를 변경\n",
    "    * batch 내의 동일한 위치의 embedding 값을 기준으로 $\\mu, \\sigma^2$를 계산\n",
    "        * eg. $\\mu_{1} = \\frac{(embed_{1,1} + embed_{2,1} + embed_{3,1} + ... + embed_{batch size, 1})}{batch size}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0112,  0.6694,  0.2133, -2.1240],\n",
      "         [ 0.8342, -1.1157,  0.0988, -1.4930],\n",
      "         [-0.6723,  1.6039, -0.3313, -1.2899],\n",
      "         [-0.7092, -0.5581, -0.7460,  0.6279],\n",
      "         [ 1.6754, -0.0950, -0.4269,  0.4937]],\n",
      "\n",
      "        [[-1.0764,  0.3514,  0.1356,  0.8197],\n",
      "         [ 0.1783,  0.4700,  1.7466, -0.7191],\n",
      "         [ 1.2850,  0.6923, -0.9918, -0.2960],\n",
      "         [-1.3285,  0.7479, -0.0114,  1.9775],\n",
      "         [ 1.2202, -0.3651, -1.3004, -1.2020]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_1d_norm = nn.BatchNorm1d(embed_dim)\n",
    "output = batch_1d_norm(batch_embed)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Batch Normalization 구현 \n",
    "* $y = \\frac{x - E[x]}{\\sqrt{Var[x] + \\epsilon}}*\\gamma + \\beta$\n",
    "* $\\gamma, \\beta$는 학습 가능한 paramters( weight, bias )\n",
    "* var 계산 시, unbiased=False으로 설정하지 않으면 Bessel’s correction을 통해 표본 크기를 n이 아닌 n-1을 사용하게 된다)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:\n",
      "  tensor([ 0.6264, -0.1400, -0.0431,  0.0626, -0.0629])\n",
      " \n",
      "var:\n",
      " tensor([1.6543, 0.9625, 1.1125, 1.2423, 1.0358])\n"
     ]
    }
   ],
   "source": [
    "batch_embed = batch_embed.transpose(1, 2)\n",
    "eg_mean = torch.mean(batch_embed, dim=(0, 1))\n",
    "print('mean:\\n ', eg_mean)\n",
    "print(' ')\n",
    "eg_var = torch.var(batch_embed, dim=(0, 1), unbiased = False)\n",
    "print('var:\\n', eg_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0112,  0.6694,  0.2133, -2.1240],\n",
      "         [ 0.8342, -1.1157,  0.0988, -1.4930],\n",
      "         [-0.6723,  1.6039, -0.3313, -1.2899],\n",
      "         [-0.7092, -0.5581, -0.7460,  0.6279],\n",
      "         [ 1.6754, -0.0950, -0.4269,  0.4937]],\n",
      "\n",
      "        [[-1.0764,  0.3514,  0.1356,  0.8197],\n",
      "         [ 0.1783,  0.4700,  1.7466, -0.7191],\n",
      "         [ 1.2850,  0.6923, -0.9918, -0.2960],\n",
      "         [-1.3285,  0.7479, -0.0114,  1.9775],\n",
      "         [ 1.2202, -0.3651, -1.3004, -1.2020]]], grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 위의 결과와 동일\n",
    "eg_x_hat = (batch_embed - eg_mean) / torch.sqrt(eg_var + batch_1d_norm.eps)\n",
    "print((batch_1d_norm.weight * eg_x_hat + batch_1d_norm.bias).transpose(1, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
