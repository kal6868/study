{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sample Embedding 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784],\n",
      "         [-1.2345, -0.0431, -1.6047, -0.7521,  1.6487],\n",
      "         [-0.3925, -1.4036, -0.7279, -0.5594, -0.7688],\n",
      "         [ 0.7624,  1.6423, -0.1596, -0.4974,  0.4396],\n",
      "         [-0.7581,  1.0783,  0.8008,  1.6806,  1.2791]],\n",
      "\n",
      "        [[ 1.2964,  0.6105,  1.3347, -0.2316,  0.0418],\n",
      "         [-0.2516,  0.8599, -1.3847, -0.8712,  0.0780],\n",
      "         [ 0.5258, -0.4880,  1.1914, -0.8140, -0.7360],\n",
      "         [-0.8371, -0.9224, -0.0635,  0.6756, -0.0978],\n",
      "         [ 1.8446, -1.1845,  1.3835, -1.2024,  0.7078]]])\n"
     ]
    }
   ],
   "source": [
    "batch, sentence_len, embed_dim = 2, 5, 5\n",
    "batch_embed = torch.randn(batch, sentence_len, embed_dim)\n",
    "print(batch_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nn.LayerNorm 함수를 사용한 Nomalize \n",
    "    * embeding demension을 기준으로 $\\mu, \\sigma^2$를 이용하여 Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9.5596e-01,  6.4450e-01,  2.2894e-01, -1.9008e+00,  7.1452e-02],\n",
      "         [-7.2907e-01,  3.0826e-01, -1.0513e+00, -3.0907e-01,  1.7812e+00],\n",
      "         [ 1.1002e+00, -1.8430e+00,  1.2390e-01,  6.1422e-01,  4.6816e-03],\n",
      "         [ 4.3522e-01,  1.6136e+00, -7.9961e-01, -1.2520e+00,  2.8364e-03],\n",
      "         [-1.8792e+00,  3.1295e-01, -1.8318e-02,  1.0319e+00,  5.5265e-01]],\n",
      "\n",
      "        [[ 1.0773e+00,  1.7915e-04,  1.1375e+00, -1.3222e+00, -8.9286e-01],\n",
      "         [ 8.0589e-02,  1.5173e+00, -1.3841e+00, -7.2040e-01,  5.0664e-01],\n",
      "         [ 7.4713e-01, -5.3673e-01,  1.5900e+00, -9.4959e-01, -8.5080e-01],\n",
      "         [-1.0051e+00, -1.1509e+00,  3.1715e-01,  1.5804e+00,  2.5848e-01],\n",
      "         [ 1.1994e+00, -1.1678e+00,  8.3913e-01, -1.1818e+00,  3.1105e-01]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer_norm = nn.LayerNorm(embed_dim)\n",
    "print(layer_norm(batch_embed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Layer Normalization 구현 \n",
    "* $y = \\frac{x - E[x]}{\\sqrt{Var[x] + \\epsilon}}*\\gamma + \\beta$\n",
    "* $\\gamma, \\beta$는 학습 가능한 paramters( weight, bias \n",
    "* var 계산 시, unbiased=False으로 설정하지 않으면 Bessel’s correction을 통해 표본 크기를 n이 아닌 n-1을 사용하게 된다)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:\n",
      "  tensor([[[ 0.5776],\n",
      "         [-0.3971],\n",
      "         [-0.7704],\n",
      "         [ 0.4375],\n",
      "         [ 0.8161]],\n",
      "\n",
      "        [[ 0.6104],\n",
      "         [-0.3139],\n",
      "         [-0.0642],\n",
      "         [-0.2490],\n",
      "         [ 0.3098]]])\n",
      " \n",
      "var:\n",
      " tensor([[[1.9924],\n",
      "         [1.3193],\n",
      "         [0.1180],\n",
      "         [0.5575],\n",
      "         [0.7018]],\n",
      "\n",
      "        [[0.4055],\n",
      "         [0.5985],\n",
      "         [0.6235],\n",
      "         [0.3423],\n",
      "         [1.6374]]])\n"
     ]
    }
   ],
   "source": [
    "eg_mean = torch.mean(batch_embed, -1, keepdim=True) # E[x]\n",
    "print('mean:\\n ', eg_mean)\n",
    "print(' ')\n",
    "eg_var = torch.var(batch_embed, -1, keepdim=True, unbiased=False) # Var[x]\n",
    "print('var:\\n', eg_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'weight': tensor([1., 1., 1., 1., 1.]), 'bias': tensor([0., 0., 0., 0., 0.])})\n",
      "tensor([[[ 9.5596e-01,  6.4450e-01,  2.2894e-01, -1.9008e+00,  7.1452e-02],\n",
      "         [-7.2907e-01,  3.0826e-01, -1.0513e+00, -3.0907e-01,  1.7812e+00],\n",
      "         [ 1.1002e+00, -1.8430e+00,  1.2390e-01,  6.1422e-01,  4.6816e-03],\n",
      "         [ 4.3521e-01,  1.6136e+00, -7.9961e-01, -1.2520e+00,  2.8363e-03],\n",
      "         [-1.8792e+00,  3.1295e-01, -1.8318e-02,  1.0319e+00,  5.5265e-01]],\n",
      "\n",
      "        [[ 1.0773e+00,  1.7905e-04,  1.1375e+00, -1.3222e+00, -8.9286e-01],\n",
      "         [ 8.0589e-02,  1.5173e+00, -1.3841e+00, -7.2040e-01,  5.0664e-01],\n",
      "         [ 7.4713e-01, -5.3673e-01,  1.5900e+00, -9.4959e-01, -8.5080e-01],\n",
      "         [-1.0051e+00, -1.1509e+00,  3.1715e-01,  1.5804e+00,  2.5848e-01],\n",
      "         [ 1.1994e+00, -1.1678e+00,  8.3913e-01, -1.1818e+00,  3.1105e-01]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 위의 결과와 동일\n",
    "eg_x_hat = (batch_embed-eg_mean)/torch.sqrt(eg_var + layer_norm.eps)\n",
    "print(layer_norm.state_dict())\n",
    "print(layer_norm.weight * eg_x_hat + layer_norm.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.2181e+00,  5.2317e-01,  3.4665e-01, -1.9733e-01, -1.0546e+00],\n",
      "          [ 1.2780e+00,  1.4534e-01,  2.3105e-01,  5.6622e-02,  4.2630e-01],\n",
      "          [ 5.7501e-01, -6.4172e-01, -2.2064e+00, -7.5080e-01,  2.8140e+00],\n",
      "          [ 3.5979e-01, -1.3407e+00, -5.8537e-01,  5.3619e-01,  5.2462e-01],\n",
      "          [ 1.1412e+00,  5.1644e-02,  7.2811e-01, -7.1064e-01, -1.0495e+00]],\n",
      "\n",
      "         [[ 6.0390e-01, -1.7223e+00, -8.2777e-01,  1.3347e+00,  4.8354e-01],\n",
      "          [-1.9756e-01,  1.2683e+00,  7.8459e-01,  2.8647e-02,  6.4076e-01],\n",
      "          [ 5.8325e-01,  1.0669e+00, -4.5015e-01, -6.7875e-01,  5.7432e-01],\n",
      "          [ 4.0476e-01,  1.7847e-01,  2.6491e-01,  1.2732e+00, -1.3109e-03],\n",
      "          [-3.0360e-01, -9.8644e-01,  1.2330e-01, -5.9915e-01,  4.7706e-01]],\n",
      "\n",
      "         [[ 7.2618e-01,  9.1152e-02, -3.8907e-01,  5.2792e-01,  1.0311e+00],\n",
      "          [-7.0477e-01,  1.3254e-01,  7.6424e-01,  1.0950e+00,  3.3989e-01],\n",
      "          [ 7.1997e-01,  4.1141e-01, -5.7332e-01,  5.0686e-01, -1.4364e+00],\n",
      "          [-1.1299e+00, -1.3603e-01,  1.6354e+00,  6.5474e-01,  5.7600e-01],\n",
      "          [-3.6091e-01, -6.0590e-02, -1.8058e+00,  9.2543e-01, -3.7534e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0331e+00, -6.8665e-01,  6.3681e-01,  2.1755e-01, -4.6655e-02],\n",
      "          [ 1.6192e+00,  1.4506e+00,  2.6948e-01, -2.1038e-01, -7.3280e-01],\n",
      "          [ 1.0430e-01,  1.0414e+00, -3.9973e-01, -4.6569e-01,  1.6048e+00],\n",
      "          [-2.4801e+00, -4.1754e-01, -1.1955e+00,  8.1234e-01, -3.0628e-01],\n",
      "          [-3.3016e-01,  2.4859e-02, -3.4595e-01,  2.8683e-01, -7.3084e-01]],\n",
      "\n",
      "         [[ 1.7482e-01, -1.0939e+00,  9.6334e-01, -3.0953e-01,  1.2888e+00],\n",
      "          [ 5.2295e-02, -1.5469e+00,  7.5671e-01,  7.7552e-01,  2.0265e+00],\n",
      "          [ 9.8121e-01, -6.4012e-01, -8.0566e-01, -2.0758e-01, -9.3195e-01],\n",
      "          [-1.5910e+00, -1.1360e+00, -5.2260e-01,  7.1654e-01,  1.5335e+00],\n",
      "          [-1.9267e+00,  1.2785e-01,  1.0229e+00, -5.5580e-01,  7.0427e-01]],\n",
      "\n",
      "         [[ 7.0988e-01, -1.5326e+00, -7.2513e-01,  9.6245e-01, -3.3702e-01],\n",
      "          [-1.1753e+00,  3.5806e-01,  4.7877e-01,  1.3537e+00,  1.3032e+00],\n",
      "          [ 4.8787e-01,  1.1340e+00, -3.5556e-01,  3.6183e-01,  1.9993e+00],\n",
      "          [ 6.6301e-01,  7.0473e-01,  2.1274e-02, -8.2927e-01, -1.0809e+00],\n",
      "          [-7.8385e-01,  5.0710e-01,  8.2078e-02,  4.4398e-01, -7.2403e-01]]]])\n"
     ]
    }
   ],
   "source": [
    "batch, channel, height, width = 2, 3, 5, 5\n",
    "batch_img = torch.randn(batch, channel, height, width)\n",
    "print(batch_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nn.LayerNorm 함수를 사용한 Nomalize \n",
    "    * image demension을 기준으로 $\\mu, \\sigma^2$를 이용하여 Normalize\n",
    "        * 1\\) channel dimension을 기준으로 $\\mu, \\sigma^2$ 산출\n",
    "        * 2\\) 1)에서 height 기준으로 $\\mu, \\sigma^2$ 산출\n",
    "        * 3\\) 2)에서 width 기준으로 $\\mu, \\sigma^2$ 산출\n",
    "        * 각 image의 $\\mu, \\sigma^2$ 값 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.3414e+00,  4.2670e-01,  2.2730e-01, -3.8722e-01, -1.3556e+00],\n",
      "          [ 1.2794e+00, -1.1660e-04,  9.6711e-02, -1.0034e-01,  3.1727e-01],\n",
      "          [ 4.8526e-01, -8.8923e-01, -2.6568e+00, -1.0125e+00,  3.0146e+00],\n",
      "          [ 2.4214e-01, -1.6788e+00, -8.2557e-01,  4.4141e-01,  4.2835e-01],\n",
      "          [ 1.1249e+00, -1.0596e-01,  6.5822e-01, -9.6709e-01, -1.3498e+00]],\n",
      "\n",
      "         [[ 5.1790e-01, -2.1099e+00, -1.0994e+00,  1.3435e+00,  3.8194e-01],\n",
      "          [-3.8748e-01,  1.2685e+00,  7.2202e-01, -1.3194e-01,  5.5954e-01],\n",
      "          [ 4.9457e-01,  1.0410e+00, -6.7282e-01, -9.3106e-01,  4.8449e-01],\n",
      "          [ 2.9294e-01,  3.7307e-02,  1.3496e-01,  1.2740e+00, -1.6578e-01],\n",
      "          [-5.0727e-01, -1.2786e+00, -2.5013e-02, -8.4114e-01,  3.7461e-01]],\n",
      "\n",
      "         [[ 6.5604e-01, -6.1328e-02, -6.0381e-01,  4.3207e-01,  1.0005e+00],\n",
      "          [-9.6045e-01, -1.4579e-02,  6.9904e-01,  1.0727e+00,  2.1966e-01],\n",
      "          [ 6.4902e-01,  3.0045e-01, -8.1196e-01,  4.0829e-01, -1.7870e+00],\n",
      "          [-1.4407e+00, -3.1797e-01,  1.6832e+00,  5.7534e-01,  4.8639e-01],\n",
      "          [-5.7201e-01, -2.3275e-01, -2.2043e+00,  8.8113e-01, -5.8831e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0245e+00, -7.8950e-01,  6.0649e-01,  1.6426e-01, -1.1443e-01],\n",
      "          [ 1.6427e+00,  1.4649e+00,  2.1903e-01, -2.8712e-01, -8.3818e-01],\n",
      "          [ 4.4794e-02,  1.0333e+00, -4.8686e-01, -5.5643e-01,  1.6275e+00],\n",
      "          [-2.6813e+00, -5.0564e-01, -1.3262e+00,  7.9164e-01, -3.8828e-01],\n",
      "          [-4.1347e-01, -3.8997e-02, -4.3013e-01,  2.3733e-01, -8.3611e-01]],\n",
      "\n",
      "         [[ 1.1918e-01, -1.2191e+00,  9.5091e-01, -3.9171e-01,  1.2942e+00],\n",
      "          [-1.0058e-02, -1.6968e+00,  7.3296e-01,  7.5280e-01,  2.0724e+00],\n",
      "          [ 9.6976e-01, -7.4042e-01, -9.1503e-01, -2.8417e-01, -1.0482e+00],\n",
      "          [-1.7434e+00, -1.2634e+00, -6.1646e-01,  6.9059e-01,  1.5523e+00],\n",
      "          [-2.0975e+00,  6.9639e-02,  1.0138e+00, -6.5147e-01,  6.7765e-01]],\n",
      "\n",
      "         [[ 6.8356e-01, -1.6818e+00, -8.3009e-01,  9.4997e-01, -4.2070e-01],\n",
      "          [-1.3050e+00,  3.1246e-01,  4.3979e-01,  1.3627e+00,  1.3094e+00],\n",
      "          [ 4.4938e-01,  1.1309e+00, -4.4027e-01,  3.1644e-01,  2.0437e+00],\n",
      "          [ 6.3412e-01,  6.7813e-01, -4.2779e-02, -9.3994e-01, -1.2053e+00],\n",
      "          [-8.9203e-01,  4.6967e-01,  2.1357e-02,  4.0309e-01, -8.2893e-01]]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer_norm = nn.LayerNorm([channel, height, width])\n",
    "print(layer_norm(batch_img))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
