{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sample Embedding 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784],\n",
      "         [-1.2345, -0.0431, -1.6047, -0.7521,  1.6487],\n",
      "         [-0.3925, -1.4036, -0.7279, -0.5594, -0.7688],\n",
      "         [ 0.7624,  1.6423, -0.1596, -0.4974,  0.4396],\n",
      "         [-0.7581,  1.0783,  0.8008,  1.6806,  1.2791]],\n",
      "\n",
      "        [[ 1.2964,  0.6105,  1.3347, -0.2316,  0.0418],\n",
      "         [-0.2516,  0.8599, -1.3847, -0.8712,  0.0780],\n",
      "         [ 0.5258, -0.4880,  1.1914, -0.8140, -0.7360],\n",
      "         [-0.8371, -0.9224, -0.0635,  0.6756, -0.0978],\n",
      "         [ 1.8446, -1.1845,  1.3835, -1.2024,  0.7078]]])\n"
     ]
    }
   ],
   "source": [
    "batch, sentence_len, embed_dim = 2, 5, 5\n",
    "batch_embed = torch.randn(batch, sentence_len, embed_dim)\n",
    "print(batch_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nn.LayerNorm 함수를 사용한 Nomalize \n",
    "    * embeding demension을 기준으로 $\\mu, \\sigma^2$를 이용하여 Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9.5596e-01,  6.4450e-01,  2.2894e-01, -1.9008e+00,  7.1452e-02],\n",
      "         [-7.2907e-01,  3.0826e-01, -1.0513e+00, -3.0907e-01,  1.7812e+00],\n",
      "         [ 1.1002e+00, -1.8430e+00,  1.2390e-01,  6.1422e-01,  4.6816e-03],\n",
      "         [ 4.3522e-01,  1.6136e+00, -7.9961e-01, -1.2520e+00,  2.8364e-03],\n",
      "         [-1.8792e+00,  3.1295e-01, -1.8318e-02,  1.0319e+00,  5.5265e-01]],\n",
      "\n",
      "        [[ 1.0773e+00,  1.7915e-04,  1.1375e+00, -1.3222e+00, -8.9286e-01],\n",
      "         [ 8.0589e-02,  1.5173e+00, -1.3841e+00, -7.2040e-01,  5.0664e-01],\n",
      "         [ 7.4713e-01, -5.3673e-01,  1.5900e+00, -9.4959e-01, -8.5080e-01],\n",
      "         [-1.0051e+00, -1.1509e+00,  3.1715e-01,  1.5804e+00,  2.5848e-01],\n",
      "         [ 1.1994e+00, -1.1678e+00,  8.3913e-01, -1.1818e+00,  3.1105e-01]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer_norm = nn.LayerNorm(embed_dim)\n",
    "print(layer_norm(batch_embed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
