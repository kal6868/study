{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T15:04:30.303147Z","iopub.status.busy":"2023-10-29T15:04:30.302288Z"},"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","import re\n","import os\n","import string\n","import datetime as dt\n","import shutil\n","import json\n","import numpy as np\n","import pandas as pd\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset, Dataset\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing import text\n","\n","device = torch.device('cuda') if torch.cuda.is_available else 'cpu'\n","import datasets\n","\n","from collections import Counter"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Cosine Simularity\n","class Similarity(nn.Module):\n","    \"\"\"\n","    Dot product or cosine similarity\n","    \"\"\"\n","\n","    def __init__(self, temp = 0.05):\n","        super().__init__()\n","        self.temp = temp\n","        self.cos = nn.CosineSimilarity(dim=-1)\n","\n","    def forward(self, x, y):\n","        return self.cos(x, y) / self.temp\n","\n","# Backbone Model\n","class Custom_tf_encoder(nn.Module):\n","    def __init__(self, used_word, embed_dim, nhead, encoder_layers, dropout=0.1, max_len=500):\n","        super().__init__()\n","        self.embedding_layer = nn.Embedding(used_word, embed_dim)\n","        self.encoders = nn.ModuleList([nn.TransformerEncoderLayer(\n","            d_model=embed_dim, \n","            nhead=nhead, \n","            dim_feedforward=(embed_dim*2), \n","            dropout=dropout, \n","            activation='gelu', \n","            batch_first=True) for _ in range(encoder_layers)])\n","#         self.avgpool = nn.AvgPool1d(kernel_size=embed_dim)\n","#         self.fc = nn.Linear(embed_dim, 2)\n","#         self.maxpool = nn.MaxPool2d(kernel_size = (max_len,1))\n","    \n","    def mk_padding_mask(self, text):\n","        # <pad>: 0\n","        return torch.eq(text, 0)\n","        \n","    def forward(self, text):\n","        x = self.embedding_layer(text)\n","        padding_mask = self.mk_padding_mask(text).to(x.device)\n","        for layer in self.encoders:\n","            x = layer(x, src_key_padding_mask=padding_mask)\n","#         x = self.maxpool(x) # (batch, 1, embed_dim)\n","#         x = x.squeeze(1) # (batch, embed_dim)\n","#         x = self.fc(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# SIMCES Contrastive Learning Model\n","class transformer_cl(nn.Module):\n","    def __init__(self, backbone):\n","        super().__init__()\n","        self.backbone = backbone\n","        self.Similarity = Similarity()\n","        \n","    def forward(self, x):\n","        emb_a = self.backbone(x)\n","        emb_b = self.backbone(x)\n","        emb_a, emb_b = emb_a[:, -1], emb_b[:, -1]\n","        cos_sim = self.Similarity(emb_a.unsqueeze(1), emb_b.unsqueeze(0))\n","        return cos_sim\n","        "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
